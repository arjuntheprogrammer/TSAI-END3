{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Session 7.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJLZ-i_9JRYi"
      },
      "source": [
        "## TRANSLATION WITH A SEQUENCE TO SEQUENCE NETWORK AND ATTENTION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbKZi3U0JYuD"
      },
      "source": [
        "!wget https://download.pytorch.org/tutorial/data.zip\n",
        "!unzip data.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LseRGYYJVpH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b5dbce8-f245-4ea7-cd24-a90bd2488f9c"
      },
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "from torch import optim\n",
        "\n",
        "import math\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import re\n",
        "import string\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import unicodedata\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "plt.switch_backend('agg')\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1\n",
        "\n",
        "# Turn a Unicode string to plain ASCII, thanks to\n",
        "# https://stackoverflow.com/a/518232/2809427\n",
        "\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    return s\n",
        "\n",
        "\n",
        "def readLangs(lang1, lang2, reverse=False):\n",
        "    print(\"Reading lines...\")\n",
        "\n",
        "    # Read the file and split into lines\n",
        "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
        "        read().strip().split('\\n')\n",
        "\n",
        "    # Split every line into pairs and normalize\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
        "\n",
        "    # Reverse pairs, make Lang instances\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang(lang2)\n",
        "        output_lang = Lang(lang1)\n",
        "    else:\n",
        "        input_lang = Lang(lang1)\n",
        "        output_lang = Lang(lang2)\n",
        "\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "\n",
        "MAX_LENGTH = 10\n",
        "\n",
        "eng_prefixes = (\n",
        "    \"i am \", \"i m \",\n",
        "    \"he is\", \"he s \",\n",
        "    \"she is\", \"she s \",\n",
        "    \"you are\", \"you re \",\n",
        "    \"we are\", \"we re \",\n",
        "    \"they are\", \"they re \"\n",
        ")\n",
        "\n",
        "\n",
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
        "        p[1].startswith(eng_prefixes)\n",
        "\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]\n",
        "\n",
        "\n",
        "def prepareData(lang1, lang2, reverse=False):\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "\n",
        "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
        "print(random.choice(pairs))\n",
        "\n",
        "\n",
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "\n",
        "\n",
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "\n",
        "\n",
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)\n",
        "\n",
        "\n",
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(\n",
        "        max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "            input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
        "\n",
        "\n",
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)\n",
        "\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)\n",
        "\n",
        "\n",
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(\n",
        "            max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words, decoder_attentions[:di + 1]\n",
        "\n",
        "\n",
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')\n",
        "\n",
        "\n",
        "def showAttention(input_sentence, output_words, attentions):\n",
        "    # Set up figure with colorbar\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111)\n",
        "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
        "    fig.colorbar(cax)\n",
        "\n",
        "    # Set up axes\n",
        "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
        "                       ['<EOS>'], rotation=90)\n",
        "    ax.set_yticklabels([''] + output_words)\n",
        "\n",
        "    # Show label at every tick\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def evaluateAndShowAttention(input_sentence):\n",
        "    output_words, attentions = evaluate(\n",
        "        encoder1, attn_decoder1, input_sentence)\n",
        "    print('input =', input_sentence)\n",
        "    print('output =', ' '.join(output_words))\n",
        "    showAttention(input_sentence, output_words, attentions)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "Read 135842 sentence pairs\n",
            "Trimmed to 10599 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "fra 4345\n",
            "eng 2803\n",
            "['tu es fort craintive .', 'you re very timid .']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7jLcGa9faKJ"
      },
      "source": [
        "hidden_size = 256\n",
        "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "attn_decoder1 = AttnDecoderRNN(\n",
        "    hidden_size, output_lang.n_words, \n",
        "    dropout_p=0.1).to(device)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whj0Rg0wJj1m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b978d165-8217-4bda-abf2-17b0daf9224e"
      },
      "source": [
        "######################################################\n",
        "trainIters(encoder1, attn_decoder1, 75000, print_every=5000)\n",
        "evaluateRandomly(encoder1, attn_decoder1)\n",
        "######################################################"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2m 2s (- 28m 33s) (5000 6%) 2.8406\n",
            "3m 57s (- 25m 45s) (10000 13%) 2.2645\n",
            "5m 54s (- 23m 36s) (15000 20%) 1.9588\n",
            "7m 50s (- 21m 34s) (20000 26%) 1.7676\n",
            "9m 48s (- 19m 37s) (25000 33%) 1.5419\n",
            "11m 46s (- 17m 40s) (30000 40%) 1.3788\n",
            "13m 43s (- 15m 41s) (35000 46%) 1.2205\n",
            "15m 39s (- 13m 42s) (40000 53%) 1.0953\n",
            "17m 35s (- 11m 43s) (45000 60%) 1.0073\n",
            "19m 30s (- 9m 45s) (50000 66%) 0.8981\n",
            "21m 25s (- 7m 47s) (55000 73%) 0.8294\n",
            "23m 22s (- 5m 50s) (60000 80%) 0.7516\n",
            "25m 17s (- 3m 53s) (65000 86%) 0.6811\n",
            "27m 14s (- 1m 56s) (70000 93%) 0.6334\n",
            "29m 11s (- 0m 0s) (75000 100%) 0.5740\n",
            "> vous etes branches .\n",
            "= you re fashionable .\n",
            "< you re being . <EOS>\n",
            "\n",
            "> vous etes en train de gaspiller mon temps .\n",
            "= you re wasting my time .\n",
            "< you re wasting my time . <EOS>\n",
            "\n",
            "> vous etes sournoise .\n",
            "= you re sneaky .\n",
            "< you re sneaky . <EOS>\n",
            "\n",
            "> je suis ceinture noire de karate .\n",
            "= i m a black belt in karate .\n",
            "< i m a black belt in karate . <EOS>\n",
            "\n",
            "> je ne suis pas interessee par une relation .\n",
            "= i m not interested in a relationship .\n",
            "< i m not interested in a relationship . <EOS>\n",
            "\n",
            "> tu n es pas aussi petite que moi .\n",
            "= you aren t as short as me .\n",
            "< you aren t as short as me . <EOS>\n",
            "\n",
            "> tu me fais marcher .\n",
            "= you re pulling my leg .\n",
            "< you re pulling my leg . <EOS>\n",
            "\n",
            "> elle est actuellement a l hopital .\n",
            "= she s in the hospital now .\n",
            "< she is busy at the . . <EOS>\n",
            "\n",
            "> je ne veux pas m en meler .\n",
            "= i m staying out of it .\n",
            "< i m not afraid of it . <EOS>\n",
            "\n",
            "> il est mon meilleur ami .\n",
            "= he s my best friend .\n",
            "< he is my best friend . <EOS>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHdPm8QOKg9H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e07c67ab-74b2-434d-9586-56b8aa89532e"
      },
      "source": [
        "######################################################\n",
        "\n",
        "output_words, attentions = evaluate(\n",
        "    encoder1, attn_decoder1, \"je suis trop froid .\")\n",
        "plt.matshow(attentions.numpy())\n",
        "\n",
        "######################################################"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fe0d2ad8350>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OJDJ_7dKlpW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0fd4d0f-f329-42b5-f62f-7928a8a5d34e"
      },
      "source": [
        "######################################################\n",
        "\n",
        "evaluateAndShowAttention(\"elle a cinq ans de moins que moi .\")\n",
        "evaluateAndShowAttention(\"elle est trop petit .\")\n",
        "evaluateAndShowAttention(\"je ne crains pas de mourir .\")\n",
        "evaluateAndShowAttention(\"c est un jeune directeur plein de talent .\")\n",
        "\n",
        "######################################################"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input = elle a cinq ans de moins que moi .\n",
            "output = she s five years younger than me . <EOS>\n",
            "input = elle est trop petit .\n",
            "output = she s too drunk . <EOS>\n",
            "input = je ne crains pas de mourir .\n",
            "output = i m not afraid of die . <EOS>\n",
            "input = c est un jeune directeur plein de talent .\n",
            "output = he s a talented young worker . <EOS>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unDjLwk5yKs-"
      },
      "source": [
        "## Evaluation Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mAqhgOI-CQu"
      },
      "source": [
        "def getDataForEvaluation(encoder, decoder, n=1000):\n",
        "  target, predicted = [], []\n",
        "  for i in range(n):\n",
        "    pair = random.choice(pairs)\n",
        "    output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
        "    output_sentence = ' '.join(output_words[:-1])\n",
        "    \n",
        "    target.append(pair[1])\n",
        "    predicted.append(output_sentence)\n",
        "    \n",
        "  return target, predicted\n",
        "\n",
        "target, predicted = getDataForEvaluation(encoder1, attn_decoder1)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67y8CI_ixms_"
      },
      "source": [
        "### Recall, Precision, and F1 Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gdh-dmAcx210",
        "outputId": "3d5a3ee6-f398-4ea2-ce95-3c5f63ef4c1f"
      },
      "source": [
        "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "def prepareDataForEvaluation(target, predicted):\n",
        "  y_true, y_pred = [], []\n",
        "\n",
        "  for t, p in zip(target, predicted):\n",
        "    y_true.append(0)\n",
        "    if(t==p):\n",
        "      y_pred.append(0)\n",
        "    else:\n",
        "      y_pred.append(1)\n",
        "  return y_true, y_pred\n",
        "\n",
        "y_true, y_pred = prepareDataForEvaluation(target, predicted)\n",
        "print(precision_recall_fscore_support(y_true, y_pred, average='macro', zero_division=0))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0.5, 0.278, 0.3573264781491003, None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_lbpxz2xxGT"
      },
      "source": [
        "### BLEU \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uODHiD3Tx3Tg",
        "outputId": "5d0bcc30-3940-4dda-d49e-a8f73b058705"
      },
      "source": [
        "# https://pytorch.org/text/stable/data_metrics.html\n",
        "from torchtext.data.metrics import bleu_score\n",
        "\n",
        "def prepareDataForEvaluation(target, predicted):\n",
        "  candidate_corpus, references_corpus = [], []\n",
        "\n",
        "  for t, p in zip(target, predicted):\n",
        "    candidate_corpus.append(t.split(\" \"))\n",
        "    references_corpus.append([p.split(\" \")])\n",
        "  \n",
        "  return candidate_corpus, references_corpus\n",
        "\n",
        "candidate_corpus, references_corpus = prepareDataForEvaluation(target, predicted)\n",
        "bleu_score(candidate_corpus, references_corpus)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7118354439735413"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WBJ0S_vG0ZX",
        "outputId": "babb1bcf-7f39-4a7e-c849-e6011227c003"
      },
      "source": [
        "print(candidate_corpus[:5])\n",
        "print(references_corpus[:5])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['they', 're', 'jittery', '.'], ['you', 'are', 'tired', 'and', 'so', 'am', 'i', '.'], ['you', 're', 'supposed', 'to', 'be', 'resting', '.'], ['he', 's', 'a', 'movie', 'buff', '.'], ['i', 'am', 'familiar', 'with', 'this', 'subject', '.']]\n",
            "[[['they', 're', 'jittery', '.']], [['you', 'are', 'tired', 'and', 'so', 'am', '.']], [['you', 're', 'supposed', 'to', 'be', '.']], [['he', 's', 'a', 'movie', '.', '.']], [['i', 'am', 'accustomed', 'to', 'go', 'this', '.']]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doQKReYWx13U"
      },
      "source": [
        "### BERTScore"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78Nsf5GBLNX-"
      },
      "source": [
        "!pip install bert-score\n",
        "\n",
        "from bert_score import BERTScorer\n",
        "bert_scorer = BERTScorer(lang=\"en\", rescale_with_baseline=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzwU0qLUxmN5",
        "outputId": "b76ec3df-905b-4198-d66b-ce3ca41cc482"
      },
      "source": [
        "# https://github.com/Tiiiger/bert_score\n",
        "# https://torchmetrics.readthedocs.io/en/latest/references/modules.html?highlight=BERTScore#bertscore\n",
        "# https://torchmetrics.readthedocs.io/en/latest/references/modules.html#text\n",
        "# https://towardsdatascience.com/machine-translation-evaluation-with-sacrebleu-and-bertscore-d7fdb0c47eb3\n",
        "# https://colab.research.google.com/drive/1kpL8Y_AnUUiCxFjhxSrxCsc6-sDMNb_Q#scrollTo=Bu2lZchuMjzP\n",
        "\n",
        "\n",
        "def prepareDataForEvaluation(target, predicted):\n",
        "  hyps, refs = [], []\n",
        "\n",
        "  for t, p in zip(target, predicted):\n",
        "    hyps.append(t)\n",
        "    refs.append([p])\n",
        "  \n",
        "  return hyps, refs\n",
        "\n",
        "hyps, refs = prepareDataForEvaluation(target, predicted)\n",
        "P, R, F1 = bert_scorer.score(hyps, refs)\n",
        "print(P.mean(), R.mean(), F1.mean())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.8281) tensor(0.8336) tensor(0.8309)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czi_il1-KiWg"
      },
      "source": [
        ""
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4Fd0d9kxzjW"
      },
      "source": [
        "### Perplexity\n",
        "- explain whether you are using bigram, trigram, or something else, what does your PPL score represent?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swo5dwuFx39t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76ce7941-df0b-427f-d38b-4db10c2be604"
      },
      "source": [
        "# https://huggingface.co/docs/transformers/perplexity\n",
        "\n",
        "import math\n",
        "\n",
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
        "                      for i in range(n_iters)]\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s | (%d %d%%) | AVG_LOSS = %.4f | PPL = %7.3f |'  % (\n",
        "                timeSince(start, iter / n_iters), iter, \n",
        "                iter / n_iters * 100, print_loss_avg, \n",
        "                math.exp(print_loss_avg))\n",
        "            )\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)\n",
        "\n",
        "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "attn_decoder1 = AttnDecoderRNN(\n",
        "    hidden_size, output_lang.n_words, \n",
        "    dropout_p=0.1).to(device)\n",
        "trainIters(encoder1, attn_decoder1, 10000, print_every=1000)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0m 22s (- 3m 20s) | (1000 10%) | AVG_LOSS = 2.5655 | PPL =  13.007 |\n",
            "0m 43s (- 2m 52s) | (2000 20%) | AVG_LOSS = 2.4417 | PPL =  11.493 |\n",
            "1m 4s (- 2m 29s) | (3000 30%) | AVG_LOSS = 2.3340 | PPL =  10.319 |\n",
            "1m 25s (- 2m 8s) | (4000 40%) | AVG_LOSS = 2.2747 | PPL =   9.725 |\n",
            "1m 46s (- 1m 46s) | (5000 50%) | AVG_LOSS = 2.2312 | PPL =   9.311 |\n",
            "2m 7s (- 1m 24s) | (6000 60%) | AVG_LOSS = 2.1697 | PPL =   8.756 |\n",
            "2m 27s (- 1m 3s) | (7000 70%) | AVG_LOSS = 2.0685 | PPL =   7.913 |\n",
            "2m 48s (- 0m 42s) | (8000 80%) | AVG_LOSS = 2.0142 | PPL =   7.495 |\n",
            "3m 9s (- 0m 21s) | (9000 90%) | AVG_LOSS = 1.9480 | PPL =   7.015 |\n",
            "3m 30s (- 0m 0s) | (10000 100%) | AVG_LOSS = 1.9129 | PPL =   6.772 |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RKfzLwvfkol"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}