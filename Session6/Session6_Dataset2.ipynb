{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Session6-Dataset2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebupkScS1xsl"
      },
      "source": [
        "!wget https://github.com/arjuntheprogrammer/TSAI-END3/files/7604488/train.csv.zip\n",
        "!unzip  train.csv.zip"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoX6sO6r2iUw"
      },
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "from torch import optim\n",
        "\n",
        "import math\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import re\n",
        "import string\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import unicodedata\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "plt.switch_backend('agg')\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1\n",
        "\n",
        "# Turn a Unicode string to plain ASCII, thanks to\n",
        "# https://stackoverflow.com/a/518232/2809427\n",
        "\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "\n",
        "\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    return s\n",
        "\n",
        "def readFile(input_name, output_name):\n",
        "    pairs = []\n",
        "    # Read the file and split into lines\n",
        "    file_path = '/content/train.csv'\n",
        "    \n",
        "    print(\"Reading lines: \", file_path)\n",
        "    lines = open(\n",
        "     file_path,\n",
        "      encoding='utf-8',\n",
        "      errors='ignore'\n",
        "    ).read().strip().split('\\n')\n",
        "\n",
        "    # Split every line into pairs and normalize\n",
        "    for l in lines:\n",
        "      split_list = l.split(',\"')\n",
        "      try:\n",
        "        if(split_list[5] == '1\"'):\n",
        "          pairs.extend([[normalizeString(s) for s in split_list[3:5]]])\n",
        "      except:\n",
        "        print(\"error split_list = \", split_list)\n",
        "  \n",
        "    input_question = Lang(input_name)\n",
        "    output_question = Lang(output_name)\n",
        "    return input_question, output_question, pairs\n",
        "\n",
        "MAX_LENGTH = 10\n",
        "\n",
        "def filterPair(p):\n",
        "    return (len(p[0].split(' ')) < MAX_LENGTH and \n",
        "        len(p[1].split(' ')) < MAX_LENGTH)\n",
        "\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]\n",
        "\n",
        "\n",
        "def prepareData(input_name, output_name):\n",
        "    input_question, output_question, pairs = readFile(input_name, output_name)\n",
        "    print(\"\\nRead %s sentence pairs\" % len(pairs))\n",
        "    \n",
        "    pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    \n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_question.addSentence(pair[0])\n",
        "        output_question.addSentence(pair[1])\n",
        "    \n",
        "    print(\"Counted words:\")\n",
        "    print(input_question.name, input_question.n_words)\n",
        "    print(output_question.name, output_question.n_words)\n",
        "    return input_question, output_question, pairs\n",
        "\n",
        "\n",
        "input_question, output_question, pairs = prepareData('input_ques', 'output_ques')\n",
        "print(\"\\n\\nrandom.choice(pairs) = \\n\", random.choice(pairs))\n",
        "\n",
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "\n",
        "\n",
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.output_size = output_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "\n",
        "\n",
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_question, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_question, pair[1])\n",
        "    return (input_tensor, target_tensor)\n",
        "\n",
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, \n",
        "          encoder_optimizer, decoder_optimizer, criterion, \n",
        "          max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(\n",
        "        max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "            input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
        "\n",
        "\n",
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)\n",
        "\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)\n",
        "\n",
        "\n",
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_question, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(\n",
        "            max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_question.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words, decoder_attentions[:di + 1]\n",
        "\n",
        "\n",
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')\n",
        "\n",
        "\n",
        "def showAttention(input_sentence, output_words, attentions):\n",
        "    # Set up figure with colorbar\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111)\n",
        "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
        "    fig.colorbar(cax)\n",
        "\n",
        "    # Set up axes\n",
        "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
        "                       ['<EOS>'], rotation=90)\n",
        "    ax.set_yticklabels([''] + output_words)\n",
        "\n",
        "    # Show label at every tick\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def evaluateAndShowAttention(input_sentence):\n",
        "    output_words, attentions = evaluate(\n",
        "        encoder1, attn_decoder1, input_sentence)\n",
        "    print('input =', input_sentence)\n",
        "    print('output =', ' '.join(output_words))\n",
        "    showAttention(input_sentence, output_words, attentions)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 673
        },
        "id": "_ts1RIWh9RIT",
        "outputId": "10f09383-f797-4b4c-dcb2-b43b9606802c"
      },
      "source": [
        "######################################################\n",
        "\n",
        "hidden_size = 256\n",
        "\n",
        "encoder1 = EncoderRNN(input_question.n_words, hidden_size).to(device)\n",
        "attn_decoder1 = AttnDecoderRNN(\n",
        "    hidden_size, output_question.n_words, dropout_p=0.1).to(device)\n",
        "\n",
        "trainIters(encoder1, attn_decoder1, 75000, print_every=5000)\n",
        "\n",
        "######################################################"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3m 45s (- 52m 39s) (5000 6%) 3.9392\n",
            "7m 26s (- 48m 21s) (10000 13%) 3.4138\n",
            "11m 6s (- 44m 26s) (15000 20%) 3.1591\n",
            "14m 46s (- 40m 37s) (20000 26%) 2.9740\n",
            "18m 24s (- 36m 49s) (25000 33%) 2.8492\n",
            "22m 4s (- 33m 6s) (30000 40%) 2.7348\n",
            "25m 44s (- 29m 24s) (35000 46%) 2.6168\n",
            "29m 23s (- 25m 43s) (40000 53%) 2.5657\n",
            "33m 4s (- 22m 3s) (45000 60%) 2.4589\n",
            "36m 44s (- 18m 22s) (50000 66%) 2.4114\n",
            "40m 24s (- 14m 41s) (55000 73%) 2.3697\n",
            "44m 6s (- 11m 1s) (60000 80%) 2.2633\n",
            "47m 44s (- 7m 20s) (65000 86%) 2.2118\n",
            "51m 24s (- 3m 40s) (70000 93%) 2.1785\n",
            "55m 3s (- 0m 0s) (75000 100%) 2.1361\n",
            "> how do i get my uan number ? \n",
            "= how i obtain my uan number ? \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBQRwBvAXtBw",
        "outputId": "25993598-c2bc-48d4-a4d4-b9c9b7dcad44"
      },
      "source": [
        "evaluateRandomly(encoder1, attn_decoder1)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> why am i getting bored ? \n",
            "= why am i bored ? \n",
            "< why am i so so ? ?  <EOS>\n",
            "\n",
            "> what is the best optical illusion ? \n",
            "= what are some optical illusions ? \n",
            "< what is best optical ?  <EOS>\n",
            "\n",
            "> how did donald trump win ? \n",
            "= how did trump become president ? \n",
            "< how did donald trump winning ?  <EOS>\n",
            "\n",
            "> is masturbating harmful for the body ? \n",
            "= why masturbating is good ? \n",
            "< how masturbating is good ?  <EOS>\n",
            "\n",
            "> are you a team player interview question ? \n",
            "= are you a team player ? \n",
            "< are you good team ?  <EOS>\n",
            "\n",
            "> what is the meaning of covalent bond ? \n",
            "= what is covalent bonding ? \n",
            "< what is a bond ?  <EOS>\n",
            "\n",
            "> how do i prepare for tnpsc group ? \n",
            "= how to prepare for tnpsc group exam ? \n",
            "< how can i prepare for upsc ?  <EOS>\n",
            "\n",
            "> how do you interpret dreams ? \n",
            "= how do i interpret dreams ? \n",
            "< how do you interpret your dreams ?  <EOS>\n",
            "\n",
            "> how can i hack a facebook account ? \n",
            "= is it possible to hack fb ? \n",
            "< how do i hack a facebook ?   <EOS>\n",
            "\n",
            "> how can i learn graphic designing ? \n",
            "= how can you learn graphic designing ? \n",
            "< how can i learn graphic ?  <EOS>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYwtMP_-Aboa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c91e5ab5-60e2-4764-d050-5bae4ff8a1ea"
      },
      "source": [
        "######################################################\n",
        "\n",
        "evaluateAndShowAttention(\"should you post picture on social media ?\")\n",
        "evaluateAndShowAttention(\"how can i control on my anger ?\")\n",
        "evaluateAndShowAttention(\"will google purchase twitter ?\")\n",
        "evaluateAndShowAttention(\"how can one increase concentration ?\")\n",
        "\n",
        "######################################################"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input = should you post picture on social media ?\n",
            "output = should you ever on media media ?  <EOS>\n",
            "input = how can i control on my anger ?\n",
            "output = how can i control my anger ?  <EOS>\n",
            "input = will google purchase twitter ?\n",
            "output = will google acquire ?  <EOS>\n",
            "input = how can one increase concentration ?\n",
            "output = how do i increase my ?  ? <EOS>\n"
          ]
        }
      ]
    }
  ]
}