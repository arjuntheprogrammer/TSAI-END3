{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FINAL Session_10.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [
        "6X7eV7sG9PEc",
        "1DDRlCr59anG",
        "7w1BmsXv921L",
        "NAZp-fW9-FyI",
        "R2d0YoeC-fn7",
        "hypAM88C-rPA",
        "D-24T6Dh-yEI",
        "d2CkmmKA-2o2",
        "cWUstn4s--JQ",
        "mW4_eHG3_RX9",
        "UyCd2aY7_VXc",
        "Gds8KcWy_mez",
        "VPXJScv0_tgM",
        "tn6Jpxtt_yqT",
        "DTq6M7-a_2r2"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Session 10 - Transformers Review\n",
        "\n",
        "- Train the same code, but on different data.\n",
        "- If you have n-classes, your accuracy MUST be more than 4 * 100 / n.\n",
        "- Submit the Github link, that includes your notebook with training logs, and proper readme file.\n",
        "\n",
        " \n",
        "\n"
      ],
      "metadata": {
        "id": "zXnXofqi9Dy3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## INSTALLATIONS AND IMPORTS"
      ],
      "metadata": {
        "id": "6X7eV7sG9PEc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ItxVxQnqgayA"
      },
      "outputs": [],
      "source": [
        "%%bash \n",
        "\n",
        "python -m spacy download en_core_web_sm\n",
        "python -m spacy download nl_core_news_sm\n",
        "python -m spacy download en\n",
        "python -m spacy download nl"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchtext"
      ],
      "metadata": {
        "id": "hOc27YLPkEoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchtext.legacy.data import Field, TabularDataset, BucketIterator  \n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "# from torchtext.datasets import IWSLT2017\n",
        "from typing import Iterable, List\n",
        "\n",
        "import spacy\n",
        "import numpy as np\n",
        "\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "OxyHH5OkqBOQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erGRorlF_PrV",
        "outputId": "c651155f-1ff5-4431-819e-6d43818abfc2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "id": "Z8h54Xj7-ofO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GET DATA\n",
        "\n",
        "Download data from the following website:\n",
        "https://www.manythings.org/anki/\n",
        "\n",
        "Dataset Link:\n",
        "https://www.manythings.org/anki/nld-eng.zip\n",
        "\n",
        "- download data saved in drive folder\n",
        "- unzip the data"
      ],
      "metadata": {
        "id": "1DDRlCr59anG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSy7wapHjKOW",
        "outputId": "42bf4d8c-3d12-4542-d67d-c72e97f93fd2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "source='/content/drive/MyDrive/Courses/TSAI/END3.0/Session10/data/nld-eng.zip'\n",
        "destination='/content/nld-eng.zip'\n",
        "shutil.copyfile(source, destination)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "D5d2zSHZl-ZK",
        "outputId": "cd1ccf8e-2854-4518-8814-b2f52b9b2e27"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/nld-eng.zip'"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/nld-eng.zip'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cx4d1QhrkpIE",
        "outputId": "ab932ca0-9b1a-4325-89f6-a0997996e6f9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/nld-eng.zip\n",
            "replace _about.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: _about.txt              \n",
            "replace nld.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: nld.txt                 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## USE PANDAS TO PARSE DATA FROM TXT FILE"
      ],
      "metadata": {
        "id": "7w1BmsXv921L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/content/nld.txt',sep=\"\\t\",header=None)\n",
        "df.columns=['TRG','SRC','hh']\n",
        "df=df[['TRG','SRC']]\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "xf-fvHsenTF6",
        "outputId": "91fa6db1-28b8-4f7d-ff58-91579cf62759"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b56adbf6-4971-4a0b-b350-5951a2314805\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TRG</th>\n",
              "      <th>SRC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Lopen!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Vooruit.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Hoi.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>HÃ©!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Hai!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b56adbf6-4971-4a0b-b350-5951a2314805')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b56adbf6-4971-4a0b-b350-5951a2314805 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b56adbf6-4971-4a0b-b350-5951a2314805');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   TRG       SRC\n",
              "0  Go.    Lopen!\n",
              "1  Go.  Vooruit.\n",
              "2  Hi.      Hoi.\n",
              "3  Hi.       HÃ©!\n",
              "4  Hi.      Hai!"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SPLIT DATA and BUILD VOCAB FROM DATA\n",
        "\n",
        "- save data to csv files\n",
        "- initiate SRC AND TRG VOCAB FIELDS\n",
        "- build SRC AND TRG VOCAB\n"
      ],
      "metadata": {
        "id": "NAZp-fW9-FyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a dataframe with 75%\n",
        "# values of original dataframe\n",
        "train_data = df.sample(frac = 0.75)\n",
        " \n",
        "# Creating dataframe with\n",
        "# rest of the 25% values\n",
        "test_data = df.drop(train_data.index)\n",
        "\n",
        "import os\n",
        "if not os.path.exists(\"/content/data/\"):\n",
        "    os.makedirs(\"/content/data/\")\n",
        "\n",
        "train_data.to_csv(\"/content/data/single_train_nl_data.csv\")\n",
        "test_data.to_csv(\"/content/data/single_test_nl_data.csv\")\n",
        "\n",
        "spacy_nl = spacy.load('nl_core_news_sm')\n",
        "spacy_en = spacy.load('en_core_web_sm')\n",
        "\n",
        "def tokenize_nl(text):\n",
        "    \"\"\"\n",
        "    Tokenizes German text from a string into a list of strings\n",
        "    \"\"\"\n",
        "    return [tok.text for tok in spacy_fr.tokenizer(text)]\n",
        "\n",
        "def tokenize_en(text):\n",
        "    \"\"\"\n",
        "    Tokenizes English text from a string into a list of strings\n",
        "    \"\"\"\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
        "\n",
        "SRC = Field(tokenize = tokenize_nl, \n",
        "            init_token = '<sos>', \n",
        "            eos_token = '<eos>', \n",
        "            lower = True, \n",
        "            batch_first = True)\n",
        "\n",
        "TRG = Field(tokenize = tokenize_en, \n",
        "            init_token = '<sos>', \n",
        "            eos_token = '<eos>', \n",
        "            lower = True, \n",
        "            batch_first = True)\n",
        "\n",
        "fields={'SRC':('SRC',SRC),'TRG':('TRG',TRG)}\n",
        "\n",
        "train_data, test_data=TabularDataset.splits(\n",
        "                                    path='data',\n",
        "                                    train='single_train_nl_data.csv',#this is the traing file\n",
        "                                    test='single_test_nl_data.csv',##this is the test file\n",
        "                                    format='csv',\n",
        "                                    fields=fields)## need to put zero if only one data is being returned https://github.com/pytorch/text/issues/474\n",
        "\n",
        "SRC.build_vocab(train_data, min_freq = 1)\n",
        "TRG.build_vocab(test_data, min_freq = 1)\n",
        "\n",
        "print(\"SRC Vocab Len = \", len(SRC.vocab))\n",
        "print(\"TRG Vocab Len = \", len(TRG.vocab))\n",
        "\n",
        "train_iterator, test_iterator = BucketIterator.splits(\n",
        "    (train_data, test_data), \n",
        "     batch_size = 64,sort=False,\n",
        "     device = device)\n",
        "\n",
        "for i,batch in enumerate(train_iterator):\n",
        "    print(batch.SRC)\n",
        "    print(batch.TRG)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6s0e9EmhpW6x",
        "outputId": "5c08098d-f0f9-4316-fc6b-6948132ab147"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SRC Vocab Len =  11894\n",
            "TRG Vocab Len =  5478\n",
            "tensor([[   2,   13,   48,  ...,    1,    1,    1],\n",
            "        [   2,   11, 2400,  ...,    1,    1,    1],\n",
            "        [   2,    6,   26,  ...,    1,    1,    1],\n",
            "        ...,\n",
            "        [   2,  311,   36,  ...,    1,    1,    1],\n",
            "        [   2,    5,   76,  ...,    1,    1,    1],\n",
            "        [   2,   28,    7,  ...,    1,    1,    1]], device='cuda:0')\n",
            "tensor([[   2,    5,  101,  ...,    1,    1,    1],\n",
            "        [   2, 2332,   11,  ...,    1,    1,    1],\n",
            "        [   2,    7,   20,  ...,    1,    1,    1],\n",
            "        ...,\n",
            "        [   2,  123,    7,  ...,    1,    1,    1],\n",
            "        [   2,    5,   14,  ...,    1,    1,    1],\n",
            "        [   2,   37,   11,  ...,    1,    1,    1]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ENCODER AND ENCODER LAYER CLASS"
      ],
      "metadata": {
        "id": "R2d0YoeC-fn7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, \n",
        "                 input_dim, \n",
        "                 hid_dim, \n",
        "                 n_layers, \n",
        "                 n_heads, \n",
        "                 pf_dim,\n",
        "                 dropout, \n",
        "                 device,\n",
        "                 max_length = 100):\n",
        "        super().__init__()\n",
        "\n",
        "        self.device = device\n",
        "        \n",
        "        self.tok_embedding = nn.Embedding(input_dim, hid_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
        "        \n",
        "        self.layers = nn.ModuleList([EncoderLayer(hid_dim, \n",
        "                                                  n_heads, \n",
        "                                                  pf_dim,\n",
        "                                                  dropout, \n",
        "                                                  device) \n",
        "                                     for _ in range(n_layers)])\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
        "        \n",
        "    def forward(self, src, src_mask):\n",
        "        \n",
        "        #src = [batch size, src len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "        \n",
        "        batch_size = src.shape[0]\n",
        "        src_len = src.shape[1]\n",
        "        \n",
        "        pos = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "        \n",
        "        #pos = [batch size, src len]\n",
        "        \n",
        "        src = self.dropout((self.tok_embedding(src) * self.scale) + self.pos_embedding(pos))\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        \n",
        "        for layer in self.layers:\n",
        "            src = layer(src, src_mask)\n",
        "            \n",
        "        #src = [batch size, src len, hid dim]\n",
        "            \n",
        "        return src"
      ],
      "metadata": {
        "id": "kx7e70OO3Q2s"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, \n",
        "                 hid_dim, \n",
        "                 n_heads, \n",
        "                 pf_dim,  \n",
        "                 dropout, \n",
        "                 device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \n",
        "                                                                     pf_dim, \n",
        "                                                                     dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, src, src_mask):\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        #src_mask = [batch size, 1, 1, src len] \n",
        "                \n",
        "        #self attention\n",
        "        _src, _ = self.self_attention(src, src, src, src_mask)\n",
        "        \n",
        "        #dropout, residual connection and layer norm\n",
        "        src = self.self_attn_layer_norm(src + self.dropout(_src))\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        \n",
        "        #positionwise feedforward\n",
        "        _src = self.positionwise_feedforward(src)\n",
        "        \n",
        "        #dropout, residual and layer norm\n",
        "        src = self.ff_layer_norm(src + self.dropout(_src))\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        \n",
        "        return src"
      ],
      "metadata": {
        "id": "Qh1LLJv37qr4"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MULTI HEAD ATTENTION CLASS"
      ],
      "metadata": {
        "id": "hypAM88C-rPA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttentionLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, n_heads, dropout, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        assert hid_dim % n_heads == 0\n",
        "        \n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dim = hid_dim // n_heads\n",
        "        \n",
        "        self.fc_q = nn.Linear(hid_dim, hid_dim)\n",
        "        self.fc_k = nn.Linear(hid_dim, hid_dim)\n",
        "        self.fc_v = nn.Linear(hid_dim, hid_dim)\n",
        "        \n",
        "        self.fc_o = nn.Linear(hid_dim, hid_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
        "        \n",
        "    def forward(self, query, key, value, mask = None):\n",
        "        \n",
        "        batch_size = query.shape[0]\n",
        "        \n",
        "        #query = [batch size, query len, hid dim]\n",
        "        #key = [batch size, key len, hid dim]\n",
        "        #value = [batch size, value len, hid dim]\n",
        "                \n",
        "        Q = self.fc_q(query)\n",
        "        K = self.fc_k(key)\n",
        "        V = self.fc_v(value)\n",
        "        \n",
        "        #Q = [batch size, query len, hid dim]\n",
        "        #K = [batch size, key len, hid dim]\n",
        "        #V = [batch size, value len, hid dim]\n",
        "                \n",
        "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        \n",
        "        #Q = [batch size, n heads, query len, head dim]\n",
        "        #K = [batch size, n heads, key len, head dim]\n",
        "        #V = [batch size, n heads, value len, head dim]\n",
        "                \n",
        "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n",
        "        \n",
        "        #energy = [batch size, n heads, query len, key len]\n",
        "        \n",
        "        if mask is not None:\n",
        "            energy = energy.masked_fill(mask == 0, -1e10)\n",
        "        \n",
        "        attention = torch.softmax(energy, dim = -1)\n",
        "                \n",
        "        #attention = [batch size, n heads, query len, key len]\n",
        "                \n",
        "        x = torch.matmul(self.dropout(attention), V)\n",
        "        \n",
        "        #x = [batch size, n heads, query len, head dim]\n",
        "        \n",
        "        x = x.permute(0, 2, 1, 3).contiguous()\n",
        "        \n",
        "        #x = [batch size, query len, n heads, head dim]\n",
        "        \n",
        "        x = x.view(batch_size, -1, self.hid_dim)\n",
        "        \n",
        "        #x = [batch size, query len, hid dim]\n",
        "        \n",
        "        x = self.fc_o(x)\n",
        "        \n",
        "        #x = [batch size, query len, hid dim]\n",
        "        \n",
        "        return x, attention"
      ],
      "metadata": {
        "id": "dt0WnJAIHp6P"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionwiseFeedforwardLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, pf_dim, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.fc_1 = nn.Linear(hid_dim, pf_dim)\n",
        "        self.fc_2 = nn.Linear(pf_dim, hid_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        #x = [batch size, seq len, hid dim]\n",
        "        \n",
        "        x = self.dropout(torch.relu(self.fc_1(x)))\n",
        "        \n",
        "        #x = [batch size, seq len, pf dim]\n",
        "        \n",
        "        x = self.fc_2(x)\n",
        "        \n",
        "        #x = [batch size, seq len, hid dim]\n",
        "        \n",
        "        return x"
      ],
      "metadata": {
        "id": "6wx_n_p9Hrh5"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DECODE AND DECODER LAYER CLASS"
      ],
      "metadata": {
        "id": "D-24T6Dh-yEI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, \n",
        "                 output_dim, \n",
        "                 hid_dim, \n",
        "                 n_layers, \n",
        "                 n_heads, \n",
        "                 pf_dim, \n",
        "                 dropout, \n",
        "                 device,\n",
        "                 max_length = 100):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.device = device\n",
        "        \n",
        "        self.tok_embedding = nn.Embedding(output_dim, hid_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
        "        \n",
        "        self.layers = nn.ModuleList([DecoderLayer(hid_dim, \n",
        "                                                  n_heads, \n",
        "                                                  pf_dim, \n",
        "                                                  dropout, \n",
        "                                                  device)\n",
        "                                     for _ in range(n_layers)])\n",
        "        \n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
        "        \n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "        \n",
        "        #trg = [batch size, trg len]\n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "                \n",
        "        batch_size = trg.shape[0]\n",
        "        trg_len = trg.shape[1]\n",
        "        \n",
        "        pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "                            \n",
        "        #pos = [batch size, trg len]\n",
        "            \n",
        "        trg = self.dropout((self.tok_embedding(trg) * self.scale) + self.pos_embedding(pos))\n",
        "                \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        \n",
        "        for layer in self.layers:\n",
        "            trg, attention = layer(trg, enc_src, trg_mask, src_mask)\n",
        "        \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]\n",
        "        \n",
        "        output = self.fc_out(trg)\n",
        "        \n",
        "        #output = [batch size, trg len, output dim]\n",
        "            \n",
        "        return output, attention"
      ],
      "metadata": {
        "id": "LKAHO8iVIv5p"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, \n",
        "                 hid_dim, \n",
        "                 n_heads, \n",
        "                 pf_dim, \n",
        "                 dropout, \n",
        "                 device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.enc_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.encoder_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \n",
        "                                                                     pf_dim, \n",
        "                                                                     dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "        \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "        \n",
        "        #self attention\n",
        "        _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\n",
        "        \n",
        "        #dropout, residual connection and layer norm\n",
        "        trg = self.self_attn_layer_norm(trg + self.dropout(_trg))\n",
        "            \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "            \n",
        "        #encoder attention\n",
        "        _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)\n",
        "        \n",
        "        #dropout, residual connection and layer norm\n",
        "        trg = self.enc_attn_layer_norm(trg + self.dropout(_trg))\n",
        "                    \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        \n",
        "        #positionwise feedforward\n",
        "        _trg = self.positionwise_feedforward(trg)\n",
        "        \n",
        "        #dropout, residual and layer norm\n",
        "        trg = self.ff_layer_norm(trg + self.dropout(_trg))\n",
        "        \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]\n",
        "        \n",
        "        return trg, attention"
      ],
      "metadata": {
        "id": "nCcOU8y5L6YR"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Seq2Seq NETWORK CLASS"
      ],
      "metadata": {
        "id": "d2CkmmKA-2o2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, \n",
        "                 encoder, \n",
        "                 decoder, \n",
        "                 src_pad_idx, \n",
        "                 trg_pad_idx, \n",
        "                 device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.trg_pad_idx = trg_pad_idx\n",
        "        self.device = device\n",
        "        \n",
        "    def make_src_mask(self, src):\n",
        "        \n",
        "        #src = [batch size, src len]\n",
        "        \n",
        "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "\n",
        "        return src_mask\n",
        "    \n",
        "    def make_trg_mask(self, trg):\n",
        "        \n",
        "        #trg = [batch size, trg len]\n",
        "        \n",
        "        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "        \n",
        "        #trg_pad_mask = [batch size, 1, 1, trg len]\n",
        "        \n",
        "        trg_len = trg.shape[1]\n",
        "        \n",
        "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = self.device)).bool()\n",
        "        \n",
        "        #trg_sub_mask = [trg len, trg len]\n",
        "            \n",
        "        trg_mask = trg_pad_mask & trg_sub_mask\n",
        "        \n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        \n",
        "        return trg_mask\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "        \n",
        "        #src = [batch size, src len]\n",
        "        #trg = [batch size, trg len]\n",
        "                \n",
        "        src_mask = self.make_src_mask(src)\n",
        "        trg_mask = self.make_trg_mask(trg)\n",
        "        \n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        \n",
        "        enc_src = self.encoder(src, src_mask)\n",
        "        \n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "                \n",
        "        output, attention = self.decoder(trg, enc_src, trg_mask, src_mask)\n",
        "        \n",
        "        #output = [batch size, trg len, output dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]\n",
        "        \n",
        "        return output, attention"
      ],
      "metadata": {
        "id": "XjGTnBmAN0mI"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## INITIATE AND ASSIGN ENCODER AND DECODER"
      ],
      "metadata": {
        "id": "cWUstn4s--JQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "INPUT_DIM = len(SRC.vocab)\n",
        "OUTPUT_DIM = len(TRG.vocab)\n",
        "HID_DIM = 256\n",
        "ENC_LAYERS = 3\n",
        "DEC_LAYERS = 3\n",
        "ENC_HEADS = 8\n",
        "DEC_HEADS = 8\n",
        "ENC_PF_DIM = 512\n",
        "DEC_PF_DIM = 512\n",
        "ENC_DROPOUT = 0.1\n",
        "DEC_DROPOUT = 0.1\n",
        "\n",
        "enc = Encoder(INPUT_DIM, \n",
        "              HID_DIM, \n",
        "              ENC_LAYERS, \n",
        "              ENC_HEADS, \n",
        "              ENC_PF_DIM, \n",
        "              ENC_DROPOUT, \n",
        "              device)\n",
        "\n",
        "dec = Decoder(OUTPUT_DIM, \n",
        "              HID_DIM, \n",
        "              DEC_LAYERS, \n",
        "              DEC_HEADS, \n",
        "              DEC_PF_DIM, \n",
        "              DEC_DROPOUT, \n",
        "              device)"
      ],
      "metadata": {
        "id": "KbTvw8SdP5VJ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"INPUT_DIM = \", INPUT_DIM) # 13077\n",
        "print(\"OUTPUT_DIM = \", OUTPUT_DIM) # 9353"
      ],
      "metadata": {
        "id": "KkxLOt72xuK3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b7f46d5-345f-4f6b-b9ba-d899bd058ff9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INPUT_DIM =  11894\n",
            "OUTPUT_DIM =  5478\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SRC_PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\n",
        "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
        "\n",
        "model = Seq2Seq(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)"
      ],
      "metadata": {
        "id": "650aZnaUQMZp"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuT9rtJkQwEr",
        "outputId": "b6010772-9af8-4504-9186-ffd3872c70cc"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 9,859,942 trainable parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_weights(m):\n",
        "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
        "        nn.init.xavier_uniform_(m.weight.data)\n",
        "\n",
        "\n",
        "model.apply(initialize_weights);"
      ],
      "metadata": {
        "id": "QVFaTFngQxap"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LEARNING_RATE = 0.0005\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)"
      ],
      "metadata": {
        "id": "ddVhoOELQzAr"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=TRG_PAD_IDX)"
      ],
      "metadata": {
        "id": "M62Z2z0cQ0xH"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TRAIN_EPOCH AND EVALUATE METHODS"
      ],
      "metadata": {
        "id": "mW4_eHG3_RX9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, optimizer):\n",
        "    model.train()\n",
        "    losses = 0\n",
        "\n",
        "    count=0\n",
        "    for i, batch in enumerate(train_iterator):\n",
        "        src = batch.SRC.to(device)\n",
        "        tgt = batch.TRG.to(device)\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output, _ = model(src, tgt[:,:-1]) #[:,:-1])\n",
        "\n",
        "        output_dim = output.shape[-1]\n",
        "            \n",
        "        output = output.contiguous().view(-1, output_dim)\n",
        "        tgt = tgt[:,1:].contiguous().view(-1)\n",
        "\n",
        "\n",
        "        loss = loss_fn(output, tgt)\n",
        "        loss.backward()\n",
        "        clip = 1\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "\n",
        "        optimizer.step()\n",
        "        losses += loss.item()\n",
        "        count+=1\n",
        "    return losses / count\n",
        "\n",
        "\n",
        "def evaluate(model):\n",
        "    model.eval()\n",
        "    losses = 0\n",
        "    count=0\n",
        "    for i,batch in enumerate(test_iterator):\n",
        "        src = batch.SRC.to(device)\n",
        "        tgt = batch.TRG.to(device)[:,:-1]\n",
        "\n",
        "        output, _ = model(src, tgt[:,:-1])\n",
        "            \n",
        "        #output = [batch size, trg len - 1, output dim]\n",
        "        #trg = [batch size, trg len]\n",
        "        \n",
        "        output_dim = output.shape[-1]\n",
        "        \n",
        "        output = output.contiguous().view(-1, output_dim)\n",
        "        tgt = tgt[:,1:].contiguous().view(-1)\n",
        "\n",
        "        # output = output[1:].view(-1, output.shape[-1])\n",
        "        # tgt = tgt[1:].reshape(-1)\n",
        "        loss = loss_fn(output, tgt)\n",
        "        losses += loss.item()\n",
        "        count+=1\n",
        "\n",
        "    return losses / count\n"
      ],
      "metadata": {
        "id": "AD0mZnKHQ_qd"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## START TRAINING"
      ],
      "metadata": {
        "id": "UyCd2aY7_VXc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from timeit import default_timer as timer\n",
        "NUM_EPOCHS = 10\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "for epoch in range(1, NUM_EPOCHS+1):\n",
        "    start_time = timer()\n",
        "    train_loss = train_epoch(model, optimizer)\n",
        "    end_time = timer()\n",
        "    val_loss = evaluate(model)\n",
        "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Train PPL: {math.exp(train_loss):7.3f} | Val loss: {val_loss:.3f}, Val. PPL: {math.exp(val_loss):7.3f} | \"f\"Epoch time = {(end_time - start_time):.3f}s\"))\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(val_loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDBllah0RA36",
        "outputId": "7475af3d-deb3-462e-a796-f6e7e0abf531"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Train loss: 3.141, Train PPL:  23.130 | Val loss: 2.146, Val. PPL:   8.551 | Epoch time = 24.834s\n",
            "Epoch: 2, Train loss: 1.742, Train PPL:   5.707 | Val loss: 1.519, Val. PPL:   4.569 | Epoch time = 24.912s\n",
            "Epoch: 3, Train loss: 1.218, Train PPL:   3.379 | Val loss: 1.307, Val. PPL:   3.696 | Epoch time = 24.655s\n",
            "Epoch: 4, Train loss: 0.944, Train PPL:   2.570 | Val loss: 1.215, Val. PPL:   3.369 | Epoch time = 24.672s\n",
            "Epoch: 5, Train loss: 0.778, Train PPL:   2.177 | Val loss: 1.178, Val. PPL:   3.248 | Epoch time = 24.738s\n",
            "Epoch: 6, Train loss: 0.665, Train PPL:   1.944 | Val loss: 1.147, Val. PPL:   3.148 | Epoch time = 24.708s\n",
            "Epoch: 7, Train loss: 0.580, Train PPL:   1.787 | Val loss: 1.161, Val. PPL:   3.192 | Epoch time = 24.536s\n",
            "Epoch: 8, Train loss: 0.520, Train PPL:   1.682 | Val loss: 1.168, Val. PPL:   3.217 | Epoch time = 24.902s\n",
            "Epoch: 9, Train loss: 0.468, Train PPL:   1.597 | Val loss: 1.195, Val. PPL:   3.303 | Epoch time = 24.688s\n",
            "Epoch: 10, Train loss: 0.430, Train PPL:   1.537 | Val loss: 1.218, Val. PPL:   3.381 | Epoch time = 24.755s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## START EVALUATION"
      ],
      "metadata": {
        "id": "Gds8KcWy_mez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss = evaluate(model)\n",
        "print((f\"Test loss: {test_loss:.3f}, Test. PPL: {math.exp(test_loss):7.3f}\"))"
      ],
      "metadata": {
        "id": "7HFR97YORU5D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f083ace6-e10c-467b-e770-214311245c80"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 1.218, Test. PPL:   3.381\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DEFINE TRANSLATE SENTENCE METHOD"
      ],
      "metadata": {
        "id": "VPXJScv0_tgM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_sentence(sentence, src_field, trg_field, model, device, max_len = 50):\n",
        "    \n",
        "    model.eval()\n",
        "\n",
        "    if isinstance(sentence, str):\n",
        "        nlp = spacy.load('nl_core_news_sm')\n",
        "        tokens = [token.text.lower() for token in nlp(sentence)]\n",
        "    else:\n",
        "        tokens = [token.lower() for token in sentence]\n",
        "\n",
        "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
        "        \n",
        "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
        "\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
        "    \n",
        "    src_mask = model.make_src_mask(src_tensor)\n",
        "    \n",
        "    \n",
        "    with torch.no_grad():\n",
        "        enc_src = model.encoder(src_tensor, src_mask)\n",
        "\n",
        "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
        "\n",
        "    for i in range(max_len):\n",
        "\n",
        "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
        "\n",
        "        trg_mask = model.make_trg_mask(trg_tensor)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            output, attention = model.decoder(trg_tensor, enc_src, trg_mask, src_mask)\n",
        "        \n",
        "        pred_token = output.argmax(2)[:,-1].item()\n",
        "        \n",
        "        trg_indexes.append(pred_token)\n",
        "\n",
        "        # if pred_token == trg_field[eos_token]:\n",
        "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
        "            break\n",
        "    \n",
        "    # trg_tokens = [trg_field.vocab.get_itos()[i] for i in trg_indexes]\n",
        "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
        "    \n",
        "    return trg_tokens[1:], attention"
      ],
      "metadata": {
        "id": "8v82SVfFRWYv"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DEFINE DISPLAY ATTNETION METHOD"
      ],
      "metadata": {
        "id": "tn6Jpxtt_yqT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "def display_attention(sentence, translation, attention, n_heads = 8, n_rows = 4, n_cols = 2):\n",
        "    \n",
        "    assert n_rows * n_cols == n_heads\n",
        "    \n",
        "    fig = plt.figure(figsize=(15,25))\n",
        "    \n",
        "    for i in range(n_heads):\n",
        "        \n",
        "        ax = fig.add_subplot(n_rows, n_cols, i+1)\n",
        "        \n",
        "        _attention = attention.squeeze(0)[i].cpu().detach().numpy()\n",
        "\n",
        "        cax = ax.matshow(_attention, cmap='bone')\n",
        "\n",
        "        ax.tick_params(labelsize=12)\n",
        "        ax.set_xticklabels(['']+['<sos>']+[t.lower() for t in sentence]+['<eos>'], \n",
        "                           rotation=45)\n",
        "        ax.set_yticklabels(['']+translation)\n",
        "\n",
        "        ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "        ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "vCI5jOGGRYBn"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## START TRANSLATING SENTENCES"
      ],
      "metadata": {
        "id": "DTq6M7-a_2r2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"*\"*40)\n",
        "print(\"Dutch to English Translations:-\")\n",
        "print(\"*\"*40)\n",
        "\n",
        "for x,y in [(10,20), (900, 910), (2000, 2010)]:\n",
        "  print(\".\"*40)\n",
        "  for example_idx in range(x,y):\n",
        "\n",
        "      src = vars(test_data.examples[example_idx])['SRC']\n",
        "      trg = vars(test_data.examples[example_idx])['TRG']\n",
        "\n",
        "\n",
        "      print(\"Dutch Sentence: src = \",' '.join(src))\n",
        "      print(\"Target English Sentence trg =\" ,' '.join(trg))\n",
        "\n",
        "      translation, attention = translate_sentence(src, SRC, TRG, model, device)\n",
        "      print(\"predicted trg =\" ,' '.join(translation))\n",
        "      print(\"*\"*40)"
      ],
      "metadata": {
        "id": "JGdGsdxqRZVV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7c5acbf-9c45-40dd-9d42-339e789b32f4"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "****************************************\n",
            "Dutch to English Translations:-\n",
            "****************************************\n",
            "........................................\n",
            "Dutch Sentence: src =  rustig , rustig !\n",
            "Target English Sentence trg = relax .\n",
            "predicted trg = relax . <eos>\n",
            "****************************************\n",
            "Dutch Sentence: src =  lachen .\n",
            "Target English Sentence trg = smile .\n",
            "predicted trg = laugh . <eos>\n",
            "****************************************\n",
            "Dutch Sentence: src =  bedankt !\n",
            "Target English Sentence trg = cheers !\n",
            "predicted trg = thanks ! <eos>\n",
            "****************************************\n",
            "Dutch Sentence: src =  ik heb hem !\n",
            "Target English Sentence trg = got it !\n",
            "predicted trg = i have him ! <eos>\n",
            "****************************************\n",
            "Dutch Sentence: src =  ik ben okÃ© .\n",
            "Target English Sentence trg = i 'm ok .\n",
            "predicted trg = i 'm ok . <eos>\n",
            "****************************************\n",
            "Dutch Sentence: src =  dat kan niet !\n",
            "Target English Sentence trg = no way !\n",
            "predicted trg = that ca n't be ! <eos>\n",
            "****************************************\n",
            "Dutch Sentence: src =  echt ?\n",
            "Target English Sentence trg = really ?\n",
            "predicted trg = really ? <eos>\n",
            "****************************************\n",
            "Dutch Sentence: src =  bedankt !\n",
            "Target English Sentence trg = thanks !\n",
            "predicted trg = thanks ! <eos>\n",
            "****************************************\n",
            "Dutch Sentence: src =  dank je !\n",
            "Target English Sentence trg = thanks !\n",
            "predicted trg = thanks ! <eos>\n",
            "****************************************\n",
            "Dutch Sentence: src =  vraag tom.\n",
            "Target English Sentence trg = ask tom .\n",
            "predicted trg = ask tom . <eos>\n",
            "****************************************\n",
            "........................................\n",
            "Dutch Sentence: src =  laten we het openen .\n",
            "Target English Sentence trg = let 's open it .\n",
            "predicted trg = let 's open it . <eos>\n",
            "****************************************\n",
            "Dutch Sentence: src =  laten we vooruit duwen .\n",
            "Target English Sentence trg = let 's push on .\n",
            "predicted trg = let 's get out of <unk> . <eos>\n",
            "****************************************\n",
            "Dutch Sentence: src =  laten we er een proberen .\n",
            "Target English Sentence trg = let 's try one .\n",
            "predicted trg = let 's try there . <eos>\n",
            "****************************************\n",
            "Dutch Sentence: src =  leef je uit .\n",
            "Target English Sentence trg = live a little .\n",
            "predicted trg = keep out of you . <eos>\n",
            "****************************************\n",
            "Dutch Sentence: src =  doe de deur op slot .\n",
            "Target English Sentence trg = lock the door .\n",
            "predicted trg = lock the door . <eos>\n",
            "****************************************\n",
            "Dutch Sentence: src =  mag ik binnenkomen ?\n",
            "Target English Sentence trg = may i come in ?\n",
            "predicted trg = may i come in ? <eos>\n",
            "****************************************\n",
            "Dutch Sentence: src =  ontmoet me daar .\n",
            "Target English Sentence trg = meet me there .\n",
            "predicted trg = i met there . <eos>\n",
            "****************************************\n",
            "Dutch Sentence: src =  mannen huilen niet .\n",
            "Target English Sentence trg = men do n't cry .\n",
            "predicted trg = men do n't cry . <eos>\n",
            "****************************************\n",
            "Dutch Sentence: src =  mijn auto is rood .\n",
            "Target English Sentence trg = my car is red .\n",
            "predicted trg = my car is red . <eos>\n",
            "****************************************\n",
            "Dutch Sentence: src =  ik heb een grote hond .\n",
            "Target English Sentence trg = my dog is big .\n",
            "predicted trg = i have a big dog . <eos>\n",
            "****************************************\n",
            "........................................\n",
            "Dutch Sentence: src =  is dat een raadsel ?\n",
            "Target English Sentence trg = is that a riddle ?\n",
            "predicted trg = is that a <unk> ? <eos>\n",
            "****************************************\n",
            "Dutch Sentence: src =  is die kerel okÃ© ?\n",
            "Target English Sentence trg = is that guy cool ?\n",
            "predicted trg = is that guy ok ? <eos>\n",
            "****************************************\n",
            "Dutch Sentence: src =  is de appel rood ?\n",
            "Target English Sentence trg = is the apple red ?\n",
            "predicted trg = is the apple red ? <eos>\n",
            "****************************************\n",
            "Dutch Sentence: src =  is dit uw tas ?\n",
            "Target English Sentence trg = is this your bag ?\n",
            "predicted trg = is this your bag ? <eos>\n",
            "****************************************\n",
            "Dutch Sentence: src =  is dit jouw pen ?\n",
            "Target English Sentence trg = is this your pen ?\n",
            "predicted trg = is this your pen ? <eos>\n",
            "****************************************\n",
            "Dutch Sentence: src =  is dit uw pen ?\n",
            "Target English Sentence trg = is this your pen ?\n",
            "predicted trg = is this your pen ? <eos>\n",
            "****************************************\n",
            "Dutch Sentence: src =  is hij niet italiaans ?\n",
            "Target English Sentence trg = is n't he italian ?\n",
            "predicted trg = is n't he italian ? <eos>\n",
            "****************************************\n",
            "Dutch Sentence: src =  is het niet perfect ?\n",
            "Target English Sentence trg = is n't it perfect ?\n",
            "predicted trg = is n't it perfect ? <eos>\n",
            "****************************************\n",
            "Dutch Sentence: src =  het is begonnen te sneeuwen .\n",
            "Target English Sentence trg = it began to snow .\n",
            "predicted trg = it began to snow . <eos>\n",
            "****************************************\n",
            "Dutch Sentence: src =  het is beginnen te sneeuwen .\n",
            "Target English Sentence trg = it began to snow .\n",
            "predicted trg = it 's beginning to snow . <eos>\n",
            "****************************************\n"
          ]
        }
      ]
    }
  ]
}